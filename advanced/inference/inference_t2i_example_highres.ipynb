{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import RF\n",
    "from mmdit import MMDiT\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "rf = RF(\n",
    "    MMDiT(\n",
    "        in_channels=4,\n",
    "        out_channels=4,\n",
    "        dim=2560,\n",
    "        global_conddim=2560,\n",
    "        n_layers=36,\n",
    "        n_heads=8,\n",
    "        cond_seq_dim=2048,\n",
    "        max_seq= 64 * 64\n",
    "    ),\n",
    "    True,\n",
    ")\n",
    "rf.load_state_dict(torch.load(\"/home/ubuntu/ckpts_36L_2_highres_lr_0.006/model_28672/ema1.pt\", map_location=\"cpu\"), strict = False)\n",
    "rf.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from diffusers.image_processor import VaeImageProcessor\n",
    "from diffusers.models import AutoencoderKL\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = str(True)\n",
    "\n",
    "device = 'cuda:0'\n",
    "t5tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pile-t5-xl\", use_fast=True)\n",
    "t5tokenizer.pad_token = t5tokenizer.bos_token\n",
    "t5model = AutoModelForSeq2SeqLM.from_pretrained(\"EleutherAI/pile-t5-xl\")\n",
    "t5model = t5model.to(device).eval()\n",
    "\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sdxl-vae\").to(\"cuda:0\")\n",
    "#rf.model.extend_pe((16, 16), (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def make_cond(cond_prompts, uncond_prompts = None,):\n",
    "    if not isinstance(uncond_prompts, list):\n",
    "        uncond_prompts = [\"watermark, jpeg\"] * len(cond_prompts)\n",
    "        \n",
    "    allprompts = cond_prompts + uncond_prompts\n",
    "\n",
    "    t5_inputs = t5tokenizer(\n",
    "        allprompts,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",    \n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    t5_inputs = {k: v.to(device) for k, v in t5_inputs.items()}\n",
    "    t5_outputs = t5model.encoder(**t5_inputs)[0] # B, T, D\n",
    "    # mask that by 0 for padding tokens\n",
    "    mask = t5_inputs[\"attention_mask\"].unsqueeze(-1).expand(t5_outputs.shape)\n",
    "    t5_outputs = t5_outputs * mask\n",
    "\n",
    "    return {'c_seq': t5_outputs[:len(cond_prompts)]}, {'c_seq': t5_outputs[len(cond_prompts):]}\n",
    "\n",
    "\n",
    "captions = [\n",
    "    \"photo of realistic beautiful flamingo, reading a open book. a big stack of books is piled up next to it\",\n",
    "    # \"a painting of black and white with a beautiful red flower in the right corner.\",\n",
    "    # \"photo of mystical blue cat god, dark ancient being, cinematic, 4K, magnificent\",\n",
    "    #  \"beautiful oil painting of a steamboat in a river in the afternoon. On the side of the river is a large brick building\",\n",
    "    #  \"Anime illustration of a kangaroo holding a sign that says \\\"Starry Night\\\", in front of the Sydney Opera House sitting next to the Eiffel Tower under a blue night sky of roiling energy, exploding yellow stars, and radiating swirls of blu\",\n",
    "    # \"A shiny VW van in front of a cityscape. A smiling sloth stands on grass in front of the van and is wearing a leather jacket, a cowboy hat, a kilt and a bowtie. The sloth is holding a quarterstaff and a big book. High-contrast oil painting.\",\n",
    "    # \"A shiny robot wearing a race car suit and black visor stands proudly in front of an F1 race car. The sun is setting on a cityscape in the background. comic book illustration.\",\n",
    "    #\"A photo of a light bulb in outer space traveling the galaxy with a sailing boat inside the light bulb.\",\n",
    "    # \"A sloth in a go kart on a race track. The sloth is holding a banana in one hand. There is a banana peel on the track in the background.\",\n",
    "    # \"A raccoon wearing formal clothes, wearing a tophat and holding a cane. The raccoon is holding a garbage bag. Oil painting in the style of traditional Chinese painting.\",\n",
    "    # \"a statue of Abraham Lincoln wearing an opaque and shiny astronaut's helmet. The statue sits on the moon, with the planet Earth in the sky.\",\n",
    "    \"the words 'KEEP OFF THE GRASS' on a sign next to a lawn\",\n",
    "    #\"A dog on the left and a cat on the right drinking cocktails on the beach\",\n",
    "    # \"Shuǐmò huà, 水墨画, black and red ink, a crane in Chinese style, ink art by MSchiffer, whimsical, rough sketch, sketch1.3\",\n",
    "    # \"Beautiful abstract light rose of pastel pink color on a dark gray background, the light falls beautifully on the petals, transparent petals of a delicate and warm rose bud, glow inside the bud, dry pastel abstract, symmetrical composition, art\",\n",
    "    # \"The pixelated beach scene with a vibrant orange and pink sunset, silhouetted palm trees swaying in the breeze is a beautiful and serene sight.\",\n",
    "     ]\n",
    "conds, unconds = make_cond(captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "rf.model.forward = torch.compile(rf.model.forward, mode = 'reduce-overhead')\n",
    "#rf.model.extend_pe((16, 16), (32, 32))\n",
    "#rf.model.pe_selection_index_based_on_dim(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "STEPSIZE = 100\n",
    "L = len(conds['c_seq'])\n",
    "\n",
    "gen = torch.Generator().manual_seed(0)\n",
    "init_noise = torch.randn(L, 4, 128, 128, generator = gen).cuda()\n",
    "import math\n",
    "rat = math.sqrt(1)\n",
    "\n",
    "images = rf.sample_with_xps_tff(init_noise, conds, null_cond = unconds, sample_steps = STEPSIZE, cfg = 5.0, tff = lambda t : (rat * t / (1 + (rat - 1) *t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear all grad at context\n",
    "torch.cuda.empty_cache()\n",
    "i = 1\n",
    "x = vae.decode(images[-1][i : i + 1].cuda()/0.13025).sample\n",
    "img = VaeImageProcessor().postprocess(\n",
    "            image=x.detach(), do_denormalize=[True, True]\n",
    "        )[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_for_grid = [[] for _ in range(L)]\n",
    "\n",
    "for i, _ in enumerate(conds['c_seq'][:L]):\n",
    "    for t in range(STEPSIZE):\n",
    "        x = vae.decode(images[t][i : i + 1].cuda()/0.13025).sample\n",
    "        img = VaeImageProcessor().postprocess(\n",
    "            image=x.detach(), do_denormalize=[True, True]\n",
    "        )[0]\n",
    "        images_for_grid[i].append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_for_grid[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "import math\n",
    "\n",
    "def add_caption(image, caption, font=None):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "    text_width, text_height = 40, 40\n",
    "    text_x = 10\n",
    "    text_y = height - 3 * text_height - 10  # Slightly above the bottom of the image\n",
    "    draw.text((text_x, text_y), caption[:35], fill=\"white\", font=font)\n",
    "    draw.text((text_x, text_y + text_height + 5), caption[35:70], fill=\"white\", font=font)\n",
    "    draw.text((text_x, text_y + text_height * 2 + 5), caption[70:], fill=\"white\", font=font)\n",
    "    \n",
    "\n",
    "grid_images = []\n",
    "sL = math.ceil(math.sqrt(L))\n",
    "show_captions = [f\"{c}\" for i, c in enumerate(captions)]\n",
    "\n",
    "# Load a font\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 40)\n",
    "except IOError:\n",
    "    font = ImageFont.load_default(40)\n",
    "\n",
    "IW = 768\n",
    "IH = 768\n",
    "\n",
    "for t in range(STEPSIZE):\n",
    "    grid = Image.new('RGB', (IW * sL, IH * sL))\n",
    "    for i in range(L):\n",
    "        img = images_for_grid[i][t].copy()\n",
    "        # append bit of whitespace on the img\n",
    "        ni = Image.new('RGB', (IW, IH))\n",
    "        img = img.resize((IW, IW))\n",
    "        ni.paste(img, (0, 0))\n",
    "        img = ni\n",
    "\n",
    "        #add_caption(img, show_captions[i], font=font)\n",
    "        grid.paste(img, (IW * (i % sL), IH * (i // sL)))\n",
    "    grid_images.append(grid)\n",
    "\n",
    "# Make it a gif and make the last image longer\n",
    "grid_images += [grid_images[-1]] * 15\n",
    "\n",
    "# Display the last image\n",
    "grid_images[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_images[-1].save('output_3_stage_2.gif', save_all=True, append_images=grid_images[:-1], duration=100, loop=0)\n",
    "# \n",
    "# ffmpeg -i output_3_stage_2.gif -c:v libx264 -crf 23 -pix_fmt yuv420p output_3_stage2.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
